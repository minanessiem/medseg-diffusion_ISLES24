# Single-GPU 1M sweep config for extended training experiments
# 25% longer than 800K runs, with ensemble validation
#
# Scheduler behavior with 1M steps + 20K absolute warmup:
#   - warmup_cosine_20Ksteps: 20K warmup, 980K cosine decay
#   - LR at 400K: ~2.9e-5 (still learning strongly)
#   - LR at 500K: ~2.5e-5 (midpoint)
#   - LR at 1M: ~0 (training complete)
#
# Ensemble validation: 3 samples per input, soft_staple consensus
#
# Usage: python3 -m scripts.slurm.single_job_runner --config-name cluster_1M_sweep --gpus 1 \
#   --overrides optimizer=adamw_5e5lr_wd00

defaults:
  - cluster                              # base cluster environment
  - override /model: medsegdiff_256_4l_32c_6x4a_128t_1btl_medium_simple
  - override /dataset: isles24_emperical
  - override /loss: multitask_equal
  - override /augmentation: aggressive_2d
  - override /training: train_800Kms_ampbfloat16
  - override /scheduler: warmup_cosine_20Ksteps
  - override /diffusion: openai_ddim_50steps
  - override /logging: ddim_50steps
  - override /validation: ensemble

# Override environment settings for single-GPU training
environment:
  dataset:
    train_batch_size: 24
  training:
    output_root: '/mnt/outputs/medsegdiff_1M_sweep/'
    max_steps: 1000000

# Override ensemble validation to use 3 samples instead of default 5
validation:
  ensemble:
    num_samples: 3

