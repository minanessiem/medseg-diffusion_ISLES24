# DiffSwinTr Base Configuration
# Swin Transformer U-Net for diffusion-based segmentation
#
# Based on: "DiffSwinTr: A Diffusion Model with Swin Transformer 
#           for Brain Tumor Segmentation"
#
# This configuration matches Swin-T (Tiny) depth with our 256px images.
# Parameters: ~52.8M

architecture: "diffswintr"

# ==================== Core Dimensions ====================
image_size: 256
patch_size: 4
embed_dim: 96           # Base channel dimension (C in paper)
window_size: 8          # Attention window size (8 for 256px)

# ==================== Stage Configuration ====================
# Number of Swin blocks per encoder stage
# Swin-T style: [2, 2, 6, 2]
depths: [2, 2, 6, 2]

# Number of attention heads per stage (increases with channels)
num_heads: [3, 6, 12, 24]

# MLP expansion ratio
mlp_ratio: 4.0

# ==================== Time Embedding ====================
time_embed_dim: 256

# ==================== I/O Channels ====================
mask_channels: 1
image_channels: ${dataset.num_modalities}  # 2 for ISLES24, auto-derived from dataset
out_channels: 1

# ==================== Conditional Encoder Module ====================
cem_enabled: true
cem_fusion_mode: "add"  # "add" supported, "concat" stubbed

# ==================== Regularization ====================
drop_rate: 0.0
attn_drop_rate: 0.0
drop_path_rate: 0.1

# ==================== Training Options ====================
use_checkpoint: false   # Gradient checkpointing (not yet implemented)

